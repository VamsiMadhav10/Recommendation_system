{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VamsiMadhav10/Recommendation_system/blob/main/collaborative_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKqBBHvpsKMw",
        "outputId": "68ca6925-f472-415e-8ac8-eceadda62fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3163479 sha256=ba4eb297764f4741070f34a9e43c816aaf339f7c50dbe7e4e5a653e6ac8b972b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "HaYXjtOmFsj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_an-NJtqu11"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import ast\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from surprise import Reader, Dataset\n",
        "\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "from surprise import SVDpp, accuracy\n",
        "\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from surprise import SVD, SVDpp, NMF\n",
        "\n",
        "from surprise import SlopeOne, CoClustering\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies = pd.read_csv('/content/movies.csv')\n",
        "\n",
        "df_ratings = pd.read_csv('/content/ratings.csv')"
      ],
      "metadata": {
        "id": "q2K7ByibsI0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph According to the rating"
      ],
      "metadata": {
        "id": "nXpFVXL0F0Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "rLyu1FDDS1W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Considering only the Movies which has atleast 50 Ratings"
      ],
      "metadata": {
        "id": "wGXW2Uw9pP3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_ratings = 50\n",
        "\n",
        "print(\"Number of movies which have more than {} ratings: {}\".format(min_ratings, len(df[df[('userId', 'count')]>=min_ratings])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCsPo_J2y0sZ",
        "outputId": "f91ff7b2-7fff-48a6-cea3-bfdfcb221e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of movies which have more than 50 ratings: 1060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_top_movies = df[df[('userId', 'count')]>=min_ratings]\n",
        "\n",
        "df_ratings_with_top_movies = df_ratings[df_ratings['movieId'].isin(list(df_top_movies.index))]"
      ],
      "metadata": {
        "id": "C6nAaVlty0vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_movies_rated = 100\n",
        "\n",
        "df_users = df_ratings_with_top_movies[['movieId','userId']].groupby(['userId']).agg(['count']).sort_values(('movieId','count'),ascending=False)\n",
        "\n",
        "df_top_rating_users = df_users[df_users[('movieId', 'count')]>=min_movies_rated]\n",
        "\n",
        "top_rating_users = list(df_top_rating_users.index)\n",
        "\n",
        "df_final=df_ratings_with_top_movies[df_ratings_with_top_movies['userId'].isin(top_rating_users)]"
      ],
      "metadata": {
        "id": "TtRRGbzNy0xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Item based collaborative filtering**"
      ],
      "metadata": {
        "id": "KDU9jCOA0UbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_user_item_matrix = df_final.pivot(index='movieId',columns='userId',values='rating').fillna(0)"
      ],
      "metadata": {
        "id": "O9U3XC2Zy0z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_item_matrix_sparse = csr_matrix(df_user_item_matrix.values)"
      ],
      "metadata": {
        "id": "5xDRCq0ty02D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_item_matrix_sparse.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39iUSnDq3VK4",
        "outputId": "74819223-6d34-4c0e-cfaf-681d49073c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1060, 391)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NearestNeighbors(n_neighbors=30, metric='cosine', algorithm='brute', n_jobs=-1)\n",
        "model.fit(user_item_matrix_sparse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OKUHOPxAy04B",
        "outputId": "2175b302-f7e0-4f79-d88b-21e3dee96b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=30)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=30)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommendation using K-Means"
      ],
      "metadata": {
        "id": "Cv4vy0Implfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "index_to_movie = dict()\n",
        "\n",
        "# Filter df_movies to include only rows present in df_user_item_matrix.index\n",
        "df_titles_movies = df_movies[df_movies['movieId'].isin(df_user_item_matrix.index)].set_index('movieId')\n",
        "\n",
        "count = 0\n",
        "\n",
        "for index, row in df_titles_movies.iterrows():\n",
        "    index_to_movie[count] = row['title']\n",
        "    count += 1\n",
        "\n",
        "def recommender(model, user_item_matrix_sparse, df_movies, number_of_recommendations, movie_index):\n",
        "    try:\n",
        "        main_title = index_to_movie[movie_index]\n",
        "    except KeyError:\n",
        "        print(f\"Movie with movieId {movie_index} not found in the index.\")\n",
        "        return\n",
        "\n",
        "    dist, ind = model.kneighbors(user_item_matrix_sparse[movie_index], n_neighbors=number_of_recommendations + 1)\n",
        "\n",
        "    dist = dist[0].tolist()\n",
        "    ind = ind[0].tolist()\n",
        "\n",
        "    titles = []\n",
        "\n",
        "    for index in ind:\n",
        "        titles.append(index_to_movie.get(index, f\"Unknown movie with index {index}\"))\n",
        "\n",
        "    recommendations = list(zip(titles, dist))\n",
        "\n",
        "    # sort recommendations\n",
        "    recommendations_sorted = sorted(recommendations, key=lambda x: x[1])\n",
        "\n",
        "    # reverse recommendations, leaving out the first element\n",
        "    recommendations_sorted.reverse()\n",
        "    recommendations_sorted = recommendations_sorted[:-1]\n",
        "\n",
        "    print(\"Recommendations for movie {}: \".format(main_title))\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for (title, distance) in recommendations_sorted:\n",
        "        count += 1\n",
        "        print('{}. {}, recommendation score = {}'.format(count, title, round(distance, 3)))\n",
        "\n",
        "# Example usage\n",
        "recommender(model, user_item_matrix_sparse, df_movies, 10, 1)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"\\n------------------------------------------------\")\n",
        "print(\"Total Execution Time : {} Sec\".format(end-start))\n",
        "print(\"------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh81PJ6m7MAe",
        "outputId": "d4e3d64c-3de9-4f9d-94de-6f23e188ddd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for movie Jumanji (1995): \n",
            "1. Batman Forever (1995), recommendation score = 0.453\n",
            "2. Toy Story (1995), recommendation score = 0.452\n",
            "3. Casper (1995), recommendation score = 0.45\n",
            "4. Mrs. Doubtfire (1993), recommendation score = 0.436\n",
            "5. Twister (1996), recommendation score = 0.427\n",
            "6. Jurassic Park (1993), recommendation score = 0.423\n",
            "7. Aladdin (1992), recommendation score = 0.419\n",
            "8. Mask, The (1994), recommendation score = 0.417\n",
            "9. Lion King, The (1994), recommendation score = 0.399\n",
            "10. Home Alone (1990), recommendation score = 0.379\n",
            "\n",
            "------------------------------------------------\n",
            "Total Execution Time : 0.0612335205078125 Sec\n",
            "------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index_to_movie = dict()\n",
        "\n",
        "# df_titles_movies = df_movies.set_index('movieId').loc[df_user_item_matrix.index]\n",
        "\n",
        "# count = 0\n",
        "\n",
        "# for index, row in df_titles_movies.iterrows():\n",
        "\n",
        "#     index_to_movie[count]=row['title']\n",
        "\n",
        "#     count +=1\n",
        "\n",
        "\n",
        "# def recommender(model, user_item_matrix_sparse, df_movies, number_of_recommendations, movie_index):\n",
        "\n",
        "#     main_title = index_to_movie[movie_index]\n",
        "\n",
        "#     dist, ind = model.kneighbors(user_item_matrix_sparse[movie_index], n_neighbors=number_of_recommendations+1)\n",
        "\n",
        "#     dist = dist[0].tolist()\n",
        "\n",
        "#     ind = ind[0].tolist()\n",
        "\n",
        "#     titles = []\n",
        "\n",
        "#     for index in ind:\n",
        "\n",
        "#         titles.append(index_to_movie[index])\n",
        "\n",
        "#     recommendations = list(zip(titles,dist))\n",
        "\n",
        "#     # sort recommendations\n",
        "\n",
        "#     recommendations_sorted = sorted(recommendations, key = lambda x:x[1])\n",
        "\n",
        "#     # reverse recommendations, leaving out the first element\n",
        "\n",
        "#     recommendations_sorted.reverse()\n",
        "\n",
        "#     recommendations_sorted = recommendations_sorted[:-1]\n",
        "\n",
        "#     print(\"Recommendations for movie {}: \".format(main_title))\n",
        "\n",
        "#     count = 0\n",
        "\n",
        "#     for (title, distance) in recommendations_sorted:\n",
        "\n",
        "#         count += 1\n",
        "\n",
        "#         print('{}. {}, recommendation score = {}'.format(count, title, round(distance,3)))\n",
        "\n",
        "# recommender(model, user_item_matrix_sparse, df_movies, 10, 1)"
      ],
      "metadata": {
        "id": "VAPCtK3ly07Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With SVD++"
      ],
      "metadata": {
        "id": "n3Knez8R7lWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_SVD = df_final.sample(frac=0.01, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "XmmQEJfq7orv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minimum_rating = min(df_SVD['rating'].values)\n",
        "\n",
        "maximum_rating = max(df_SVD['rating'].values)\n",
        "\n",
        "print(\"Minimum/Maximum ratings: {}/{} \".format(minimum_rating,maximum_rating))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyG0F_fJ7ugI",
        "outputId": "a75bd47b-53c8-4dcf-a0ea-b208e13d99d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum/Maximum ratings: 0.5/5.0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(minimum_rating,maximum_rating))\n",
        "\n",
        "data = Dataset.load_from_df(df_SVD[['userId', 'movieId', 'rating']], reader)"
      ],
      "metadata": {
        "id": "9zY-AEmV7uij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = SVDpp()\n",
        "\n",
        "algo.fit(data.build_full_trainset());"
      ],
      "metadata": {
        "id": "37yCEXsz7uky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = '4'\n",
        "\n",
        "movie_id = '10'\n",
        "\n",
        "prediction = algo.predict(uid=user_id, iid=movie_id)\n",
        "\n",
        "print(\"Predicted rating of user with id {} for movie with id {}: {}\".format(user_id, movie_id, round(prediction.est,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEnP1YNj7unJ",
        "outputId": "fabc3319-2f1f-4756-d795-dd1777994ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating of user with id 4 for movie with id 10: 3.461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "def recommendations_from_SVDpp(user_id, df_user_item_matrix_SVD, algo, n_recommendations):\n",
        "\n",
        "    # determine list of unrated movies by user_id\n",
        "\n",
        "    list_of_unrated_movies = np.nonzero(df_user_item_matrix_SVD.loc[user_id].to_numpy() == 0)[0]\n",
        "\n",
        "    # set up user set with unrated movies\n",
        "\n",
        "    user_set = [[user_id, item_id, 0] for item_id in list_of_unrated_movies]\n",
        "\n",
        "\n",
        "    # generate predictions\n",
        "\n",
        "    predictions = algo.test(user_set)\n",
        "\n",
        "\n",
        "    top_n_recommendations = defaultdict(list)\n",
        "\n",
        "    for user_id, item_id, _, est, _ in predictions:\n",
        "\n",
        "        top_n_recommendations[user_id].append((item_id, est))\n",
        "\n",
        "\n",
        "    for user_id, ratings in top_n_recommendations.items():\n",
        "\n",
        "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        top_n_recommendations[user_id] = ratings[:n_recommendations]\n",
        "\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    print(\"Recommendations for user with id {}: \".format(user_id))\n",
        "\n",
        "    for movie_index, score in top_n_recommendations[user_id]:\n",
        "\n",
        "        count +=1\n",
        "\n",
        "        print('{}. {}, predicted rating = {}'.format(count, df_movies[df_movies['movieId']==movie_index]['title'].iloc[0], round(score,3)))\n",
        "\n",
        "recommendations_from_SVDpp(4, df_user_item_matrix, algo, 10)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "\n",
        "print(\"\\n------------------------------------------------\")\n",
        "print(\"Total Execution Time : {} Sec\".format(end-start))\n",
        "print(\"------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heHlJk_y9vfF",
        "outputId": "2d690771-3590-46db-9165-33f2c61c9b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user with id 4: \n",
            "1. Godfather: Part II, The (1974), predicted rating = 4.192\n",
            "2. Princess Bride, The (1987), predicted rating = 4.171\n",
            "3. Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981), predicted rating = 4.119\n",
            "4. 2001: A Space Odyssey (1968), predicted rating = 4.101\n",
            "5. Star Wars: Episode IV - A New Hope (1977), predicted rating = 4.097\n",
            "6. Indiana Jones and the Last Crusade (1989), predicted rating = 4.057\n",
            "7. Silence of the Lambs, The (1991), predicted rating = 4.054\n",
            "8. Die Hard (1988), predicted rating = 4.054\n",
            "9. Usual Suspects, The (1995), predicted rating = 4.046\n",
            "10. Pulp Fiction (1994), predicted rating = 4.046\n",
            "\n",
            "------------------------------------------------\n",
            "Total Execution Time : 0.02000713348388672 Sec\n",
            "------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def recommendations_from_SVDpp(user_id, df_user_item_matrix_SVD, algo, n_recommendations, output_file):\n",
        "\n",
        "    # determine list of unrated movies by user_id\n",
        "    list_of_unrated_movies = np.nonzero(df_user_item_matrix_SVD.loc[user_id].to_numpy() == 0)[0]\n",
        "\n",
        "    # set up user set with unrated movies\n",
        "    user_set = [[user_id, item_id, 0] for item_id in list_of_unrated_movies]\n",
        "\n",
        "    # generate predictions\n",
        "    predictions = algo.test(user_set)\n",
        "\n",
        "    top_n_recommendations = defaultdict(list)\n",
        "\n",
        "    for user_id, item_id, _, est, _ in predictions:\n",
        "        top_n_recommendations[user_id].append((item_id, est))\n",
        "\n",
        "    for user_id, ratings in top_n_recommendations.items():\n",
        "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n_recommendations[user_id] = ratings[:n_recommendations]\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    output_file.write(\"Recommendations for user with id {}: \\n\".format(user_id))\n",
        "\n",
        "    for movie_index, score in top_n_recommendations[user_id]:\n",
        "        count += 1\n",
        "        movie_title = df_movies[df_movies['movieId']==movie_index]['title'].iloc[0]\n",
        "        output_file.write('{}. {}, predicted rating = {}\\n'.format(count, movie_title, round(score, 3)))\n",
        "\n",
        "    print(\"Recommendations for user with id {}: \".format(user_id))\n",
        "\n",
        "    for movie_index, score in top_n_recommendations[user_id]:\n",
        "        count +=1\n",
        "        print('{}. {}, predicted rating = {}'.format(count, df_movies[df_movies['movieId']==movie_index]['title'].iloc[0], round(score,3)))\n",
        "\n",
        "\n",
        "# Open a file for writing\n",
        "for x in []:\n",
        "  with open('output_with_top_3_recomendations.txt', 'w') as file:\n",
        "    recommendations_from_SVDpp(x, df_user_item_matrix, algo, 3, file)\n"
      ],
      "metadata": {
        "id": "IVTzAO1u7us-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "def recommendations_from_SVDpp(user_id, df_user_item_matrix_SVD, algo, n_recommendations, output_file):\n",
        "\n",
        "    # determine list of unrated movies by user_id\n",
        "    list_of_unrated_movies = np.nonzero(df_user_item_matrix_SVD.loc[user_id].to_numpy() == 0)[0]\n",
        "\n",
        "    # set up user set with unrated movies\n",
        "    user_set = [[user_id, item_id, 0] for item_id in list_of_unrated_movies]\n",
        "\n",
        "    # generate predictions\n",
        "    predictions = algo.test(user_set)\n",
        "\n",
        "    top_n_recommendations = defaultdict(list)\n",
        "\n",
        "    for user_id, item_id, _, est, _ in predictions:\n",
        "        top_n_recommendations[user_id].append((item_id, est))\n",
        "\n",
        "    for user_id, ratings in top_n_recommendations.items():\n",
        "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n_recommendations[user_id] = ratings[:n_recommendations]\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    output_file.write(\"Recommendations for user with id {}: \\n\".format(user_id))\n",
        "\n",
        "    for movie_index, score in top_n_recommendations[user_id]:\n",
        "        count += 1\n",
        "        movie_title = df_movies[df_movies['movieId'] == movie_index]['title'].iloc[0]\n",
        "        output_file.write('{}. {}, predicted rating = {}\\n'.format(count, movie_title, round(score, 3)))\n",
        "\n",
        "    print(\"Recommendations for user with id {}: \".format(user_id))\n",
        "\n",
        "    for movie_index, score in top_n_recommendations[user_id]:\n",
        "        count += 1\n",
        "        print('{}. {}, predicted rating = {}'.format(count, df_movies[df_movies['movieId'] == movie_index]['title'].iloc[0], round(score, 3)))\n",
        "\n",
        "# Define your list of user IDs\n",
        "user_ids = [1, 2, 3, 4]\n",
        "\n",
        "# Open a file for writing\n",
        "with open('output_with_top_3_recommendations.txt', 'w') as file:\n",
        "    for user_id in user_ids:\n",
        "        recommendations_from_SVDpp(user_id, df_user_item_matrix, algo, 3, file)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "\n",
        "print(\"\\n------------------------------------------------\")\n",
        "print(\"Total Execution Time : {} Sec\".format(end-start))\n",
        "print(\"------------------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "CM0IT3d2U2BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c02dbe3-4193-42f1-e4b1-b73607eaab6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user with id 1: \n",
            "4. Nightmare Before Christmas, The (1993), predicted rating = 4.021\n",
            "5. Chinatown (1974), predicted rating = 4.006\n",
            "6. Forrest Gump (1994), predicted rating = 3.982\n",
            "Recommendations for user with id 2: \n",
            "4. Princess Bride, The (1987), predicted rating = 4.171\n",
            "5. Star Wars: Episode IV - A New Hope (1977), predicted rating = 4.097\n",
            "6. Silence of the Lambs, The (1991), predicted rating = 4.054\n",
            "Recommendations for user with id 3: \n",
            "4. Godfather: Part II, The (1974), predicted rating = 4.192\n",
            "5. Princess Bride, The (1987), predicted rating = 4.171\n",
            "6. Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981), predicted rating = 4.119\n",
            "Recommendations for user with id 4: \n",
            "4. Godfather: Part II, The (1974), predicted rating = 4.192\n",
            "5. Princess Bride, The (1987), predicted rating = 4.171\n",
            "6. Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981), predicted rating = 4.119\n",
            "\n",
            "------------------------------------------------\n",
            "Total Execution Time : 0.0433199405670166 Sec\n",
            "------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nosTntlIlTB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}